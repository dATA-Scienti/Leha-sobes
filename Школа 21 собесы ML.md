**Переобучение** (overfitting) — это ситуация, когда модель машинного обучения слишком хорошо подстраивается под тренировочные данные, включая шум и случайные флуктуации, что снижает её способность **обобщать** на новые, невидимые данные. В результате модель может показывать высокую точность на тренировочных данных, но плохо работать на тестовых или новых данных.  
Признаки переобучения:

- **Высокая точность на тренировочных данных**.
- **Низкая точность на тестовых данных**.
- Модель становится слишком сложной и хорошо запоминает детали тренировочного набора, вместо того чтобы выявлять основные закономерности.
- **Методы борьбы с переобучением:**

1. Регуляризация  
    Регуляризация — это добавление штрафов к функции потерь модели за слишком сложные гипотезы. Она помогает контролировать сложность модели и заставляет её избегать слишком больших весов.  
    **L1-регуляризация (Lasso)**: Добавляет штраф в виде суммы абсолютных значений весов модели. Это может приводить к тому, что некоторые веса становятся равными нулю, тем самым уменьшая количество активных признаков.  
    **L2-регуляризация (Ridge)**: Добавляет штраф в виде суммы квадратов весов модели. Это приводит к уменьшению всех весов модели, но без полного их исключения.  
    **Elastic Net**: Это комбинация L1 и L2 регуляризаций, которая объединяет их свойства.
2. **Снижение сложности модели**:  
    **Уменьшение количества признаков**: Если модель использует слишком много признаков, она может начать переобучаться. Один из способов борьбы — использование только значимых признаков, например, через **отбор признаков** (feature selection).  
    **Снижение количества параметров**: Если модель слишком сложная (например, нейросеть с большим количеством слоёв и узлов), её можно упростить, чтобы она не слишком точно подстраивалась под данные.
3. **Увеличение объёма данных**:  
    **Сбор большего количества данных**: Если данных слишком мало, модель может слишком сильно подстроиться под особенности небольшого набора. Увеличение объёма данных помогает модели лучше обобщать информацию.  
    **Аугментация данных**: В задачах, таких как обработка изображений или текстов, можно использовать техники аугментации данных — создание новых данных путём небольших модификаций исходных (например, вращение изображений, добавление шумов и т.д.).
4. **Использование кросс-валидации**:  
    **Кросс-валидация** (cross-validation) помогает оценить, как модель будет работать на новых данных, используя разбиение данных на несколько подмножеств. Самый популярный метод — это **k-fold кросс-валидация**, когда данные разбиваются на `k` частей, и на каждой итерации одна часть используется как тестовая, а остальные — как тренировочные.
5. **Раннее завершение обучения (Early Stopping)**:  
    В задачах с нейронными сетями можно использовать **раннее завершение обучения**. Модель обучается до тех пор, пока ошибка на валидационных данных уменьшается. Как только ошибка на валидационном наборе начинает расти, обучение прекращается, чтобы избежать переобучения.
6. **Dropout (для нейронных сетей)**:  
    **Dropout** — это техника, применяемая в нейронных сетях, при которой на каждом этапе обучения случайно отключается определённый процент нейронов. Это предотвращает зависимость модели от конкретных нейронов и улучшает её способность обобщать.

- **Методы отслеживания переобучения:**

1. **Кросс-валидация**  
    Кросс-валидация (особенно **k-fold**) позволяет отслеживать обобщающую способность модели на разных наборах данных, что помогает выявлять признаки переобучения.
2. **Проверка на тренировочных и тестовых данных**:  
    Разделение данных на тренировочные и тестовые позволяет сравнивать производительность модели на обеих выборках.  
    **High Bias (недообучение)**: Низкая точность на тренировочных данных и низкая точность на тестовых данных.  
    **High Variance (переобучение)**: Высокая точность на тренировочных данных и низкая точность на тестовых данных.
3. **Отслеживание learning curves (кривых обучения)**:  
    Кривые обучения показывают, как изменяется ошибка на тренировочных и валидационных данных по мере обучения модели. Переобучение можно наблюдать, если ошибка на тренировочных данных продолжает уменьшаться, а ошибка на валидационных данных начинает расти.  
    Пример кривых обучения:

- **Недообучение (underfitting)**: Ошибка на обеих выборках высокая.
- **Хорошее обобщение**: Ошибка на обеих выборках стабильна и низка.
- **Переобучение (overfitting)**: Ошибка на тренировочной выборке низкая, но на валидационной/тестовой — высокая.

## - Что такое регуляризация и какие виды существуют? Как регуляризация помогает избежать переобучения? 

---

**Регуляризация** — это техника, используемая для предотвращения **переобучения** (overfitting) моделей машинного обучения путем добавления штрафных (регуляризационных) членов к функции потерь модели. Регуляризация помогает уменьшить сложность модели и сделать её более способной к **обобщению**, а не к запоминанию деталей тренировочных данных.  
Модели с большим количеством параметров могут быть склонны к переобучению, так как они легко запоминают случайные шумы и особенности данных. Регуляризация вводит штраф за слишком большие значения параметров модели, что заставляет модель искать более простые и обобщенные решения.  
**Как регуляризация помогает избежать переобучения?**  
Регуляризация накладывает ограничения на величины параметров модели, что уменьшает её сложность и обобщает её поведение. Она помогает предотвратить слишком точное подстраивание модели под тренировочные данные и фокусирует её на выявлении общих закономерностей.

- **Основные виды регуляризации**

1. **L1-регуляризация (Lasso)**  
    **L1-регуляризация** (или **Lasso-регуляризация**) добавляет к функции потерь сумму **абсолютных значений весов** модели. Это приводит к занулению некоторых весов, что также выполняет функцию отбора признаков (feature selection).  
    **Функция потерь с L1-регуляризацией**:  
    $J(θ)=Jошибка(θ)+λ∑i|θi|$

- **Как это работает**: L1-регуляризация наказывает все веса, а когда их значения становятся достаточно малыми, некоторые из них становятся нулевыми. Это означает, что L1-регуляризация может автоматически исключать незначимые признаки (переменные).
- **Особенности**: L1-регуляризация склонна занулять некоторые веса, что полезно для отбора признаков.

2. **L2-регуляризация (Ridge)**  
    **L2-регуляризация** (также называемая **Ridge-регуляризация**) добавляет к функции потерь сумму квадратов всех весов модели. Это приводит к тому, что модель старается минимизировать не только ошибку, но и величину весов.  
    **Функция потерь с L2-регуляризацией**:  
    $J(θ)=Jошибка(θ)+λ∑iθi2$

- **Как это работает**: L2-регуляризация "наказывает" большие веса, заставляя модель находить такие решения, при которых параметры не слишком велики. Это приводит к более стабильным решениям и снижению склонности к переобучению.
- **Особенности**: L2-регуляризация склонна уменьшать веса, но не занулять их полностью.

3. **Elastic Net**  
    **Elastic Net** — это комбинация L1 и L2 регуляризаций. Она позволяет учитывать преимущества обеих техник, добавляя и штраф за абсолютные значения весов (L1), и штраф за квадраты весов (L2).  
    **Функция потерь с Elastic Net**:  
    $J(θ)=Jошибка(θ)+λ1∑i|θi|+λ2∑iθi2$

- **Как это работает**: Elastic Net объединяет свойства L1-регуляризации (склонность к занулению весов) и L2-регуляризации (стабилизация весов). Это делает модель более гибкой и позволяет лучше справляться с данными, в которых признаки могут быть коррелированными.

## - Что такое bias и variance, и как они влияют на модели? Как связаны шум и дисбаланс классов? 

---

**Bias** (систематическая ошибка) и **variance** (дисперсия) — это два ключевых понятия, описывающие источники ошибок в моделях машинного обучения. Их соотношение определяет способность модели обобщать информацию и производительность на новых данных. Они связаны с проблемами **недообучения** (underfitting) и **переобучения** (overfitting).

1. **Bias (систематическая ошибка)**

**Bias** — это систематическая ошибка модели.

- **Высокий bias**: Модель слишком простая, игнорирует важные зависимости в данных. Модель с высоким bias не способна эффективно обучаться и часто имеет **недообучение** (underfitting).
- **Низкий bias**: Модель способна хорошо улавливать зависимости.  
    Пример:
- Линейная регрессия на сложных данных с нелинейной зависимостью может иметь высокий bias, так как она не способна уловить сложные закономерности.

2. **Variance (дисперсия)**

**Variance** описывает, насколько модель чувствительна к **колебаниям в обучающих данных**. Модель с высокой дисперсией слишком хорошо подстраивается под тренировочные данные, включая шумы и случайные вариации, что приводит к плохой генерализации на новых данных (переобучение).

- **Высокий variance**: Модель слишком сложная, сильно подстраивается под тренировочные данные, что ведет к переобучению (overfitting).
- **Низкий variance**: Модель не слишком сильно реагирует на малые изменения в данных.  
    Пример:
- Слишком сложная модель, например, глубокая нейронная сеть, может иметь высокий variance и плохо обобщать данные на тестовом наборе.  
    **Баланс между bias и variance** — это ключевая задача в машинном обучении. На практике цель состоит в том, чтобы найти **компромисс** между этими двумя ошибками. Это часто называют **компромисс bias-variance**: Идеальная модель должна иметь низкий уровень как bias, так и variance, обеспечивая хорошую производительность как на тренировочных, так и на тестовых данных.  
    Пример:
- Линейная регрессия (низкая дисперсия, но высокий bias) может плохо работать на сложных данных.
- Полиномиальная регрессия высокой степени (низкий bias, но высокая дисперсия) может слишком точно подстраиваться под тренировочные данные, но плохо обобщать на тестовые.

Связь между **шумом** и **дисбалансом классов**

1. **Шум** в данных  
    **Шум** — это случайные или нерелевантные данные, которые не несут полезной информации, но могут влиять на обучение модели. Шум может включать:

- Ошибки в данных (например, неправильные метки классов).
- Флуктуации в данных, не связанные с основными зависимостями.  
    Шум приводит к тому, что модель начинает подстраиваться под случайные вариации в данных, что усиливает **variance** и может привести к переобучению.  
    Пример:
- В наборе данных для классификации изображений может быть шум в виде случайных артефактов на изображениях, которые не связаны с классом, но могут запутать модель.

2. **Дисбаланс классов**  
    **Дисбаланс классов** — это ситуация, когда одни классы в данных значительно преобладают над другими. Это может приводить к смещению модели в сторону более часто встречающихся классов, и модель может плохо справляться с предсказанием редких классов.

Связь между дисбалансом классов и шумом заключается в том, что в малочисленных классах шум может иметь **большее влияние**, чем в крупных классах. Если редкий класс содержит шум, это может значительно ухудшить способность модели правильно предсказывать этот класс.

Проблемы с дисбалансом классов:

- Модель может научиться предсказывать только преобладающий класс, игнорируя малочисленные классы.
- Ошибки в редких классах могут значительно влиять на качество модели, так как они сложнее поддаются коррекции.

**Шум** и **дисбаланс классов** связаны с качеством данных и могут привести к переобучению и снижению качества модели. Дисбаланс классов может усиливать влияние шума на редкие классы.

## - Как бороться с дисбалансом классов? Какие метрики устойчивы к дисбалансу классов? 

---

Методы борьбы с дисбалансом классов:

1. **Сбалансирование выборки**:

- **Oversampling**: Увеличение количества примеров из малочисленных классов (например, с помощью повторов или синтетических данных). Один из распространённых методов oversampling — **SMOTE (Synthetic Minority Over-sampling Technique)**. Генерирует новые примеры для малочисленных классов путём создания синтетических точек на основе ближайших соседей существующих данных.
- **Undersampling**: Уменьшение количества примеров из преобладающих классов, чтобы сбалансировать классы. Это может помочь сбалансировать классы, но может также привести к потере важной информации, если данных недостаточно. **Tomek Links** и **NearMiss** — это методы undersampling, которые удаляют примеры преобладающего класса, находящиеся рядом с границей между классами.
- **Комбинирование oversampling и undersampling.** Можно использовать комбинацию oversampling и undersampling для сбалансирования классов. Например, можно применить SMOTE для малочисленных классов и затем использовать undersampling для преобладающих классов.

2. **Использование весов классов**:

- В некоторых алгоритмах (например, в логистической регрессии, SVM, нейронных сетях) можно назначить больший вес ошибкам для малочисленных классов, чтобы модель обращала на них больше внимания.

3. **Альтернативные метрики**:

- Для задач с дисбалансом классов вместо точности (accuracy) лучше использовать такие метрики, как **F1-score**, **ROC-AUC**, **матрица ошибок** (confusion matrix), так как они учитывают дисбаланс классов.

4. **Алгоритмы, устойчивые к дисбалансу**

- Некоторые алгоритмы машинного обучения специально разработаны для работы с несбалансированными данными. Например:
- **Balanced Random Forest**: Модификация случайного леса, в которой каждый подмножество для обучения дерева создается с помощью undersampling для баланса классов.
- **EasyEnsemble** и **BalanceCascade**: Ансамблевые методы, сочетающие undersampling и баггинг для улучшения результатов на несбалансированных данных.

## - Какие метрики классификации и регрессии существуют? Расскажите о метриках Accuracy, Precision, Recall, F1, F1-weighted, AUC-ROC. Почему F1 выглядит именно так, почему не среднее между Recall и Precision ? Расскажи про макро/микро усреднение, расскажи про One-vs-All и про One-vs-One? Чем плоха Accuracy? 

---

Для бинарной классификации используют следующие метрики:  
**Для бинарной классификации:**

- Точность (Accuracy) для сбалансированных классов
- Полнота (Recall)
- Точность (Precision)
- F1-мера (F1-score)
- AUC-ROC (Area under the Receiver Operating Characteristic Curve)

**Для многоклассовой классификации:**

Как строится такая классификация:

- Сведение к бинарной классификации (1. one vs all - поочередно строим классификаторы, отделяя каждый класс от всех остальных, предсказание делаем на основе самого уверенного классификатора. Здесь главная проблема, что модели не знают друг о друге при обучении, здесь одна модель может выдавать значения порядка 10^6, а другая порядка 10^2, и мы будем всегда выбирать первую модель, и тут есть некоторый риск, это всегда надо контролировать. 2. all vs all - берем все пары классификаторов, С_k^2 классификаторов, и при классификации каждый класс соревнуется со своей парой, выбираем в итоге тот который чаще победил. Тут нет проблем с неотмасштабированными моделями.)
- Прямой подход: многоклассовая логистическая регрессия - есть k векторов весов для всех k классов, оператор софтмакса позволяет перевести это в распределение вероятностей, что позволяет выбрать класс.

Метрики качества для многоклассовой классификации:

- Микро-усреднение: сначала усредним все TP_k по всем классам, и FP_k по всем классам. Далее в формулу presicion подставляем усредненные ранее TP и FP. Здесь у нас большое влияние крупных классов - мы ведь усредняем эти абсолюты, а TP_k будут большие у жирных классов. Итоговая метрика будет сильнее зависеть от крупных классов.
- Макро-усреднение: сначала считаем presicion и recall для каждого класса и потом считаем средний pr и rc. Здесь все классы имеют равное влияние.

## - Что такое ошибка? Как лосс отличается от метрик? 

---

**Ошибка** в машинном обучении — это отклонение между предсказанным моделью значением и фактическим (истинным) значением. Ошибка измеряет, насколько хорошо или плохо модель справляется с задачей на наборе данных. Ошибка помогает оценить, насколько точно модель описывает данные и как она может быть улучшена.

Примеры ошибок:

- В задачах регрессии — разница между предсказанным и реальным числовым значением.
- В задачах классификации — это количество неправильно предсказанных классов.  
    **Лосс (loss)**, или **функция потерь**, — это функция, которая измеряет ошибку модели на одном примере или на всём тренировочном наборе. Функция потерь указывает, насколько хорошо модель справляется с предсказанием для данного набора данных. Задача обучения модели состоит в минимизации функции потерь, то есть уменьшении её значения до минимального возможного.  
    **Метрики** — это показатели, которые оценивают качество модели, но они не обязательно используются для её оптимизации. В отличие от функции потерь, которая минимизируется в процессе обучения, метрики помогают оценить, насколько хорошо модель работает на тестовых данных или на производственных задачах. Метрики предоставляют более интерпретируемую информацию для человека, чем функция потерь, и помогают принимать решения об улучшении модели.

## - Какие бывают функции потерь? 

---

## - Как работает логистическая регрессия? В чем разница между логистической и линейной регрессиями? 

---

- Хотим оценивать вероятности классов, получать уверенность нашей модели. По факту если модель в каком-то классе уверена на 80%, это значит что если я возьму все объекты с уверенностью 80%, то из них 80% имеют именно этот класс.
- Делается это за счет того, что мы строим сначала линейную модель на входных данных, получаем некоторый логит z, далее считаем сигмоиду 1/1+exp(-z), которая сжимает входные значения в интервал от 0 до 1.
- Для обучения модели используется логистическая функция потерь (Log Loss или кросс-энтропия), которая помогает минимизировать расхождение между предсказанными и истинными значениями. Можно это преобразовать к минимизации среднего log(1+exp(-M)), где M – отступ классификатора.

## - Как работают деревья решений? 

---

- Есть внутренние вершины которым соответствуют предикаты, задающие разбиение пространства, а есть листы, в которых мы делаем прогноз. На каждом шаге мы хотим определять индекс j признака, по которому мы разбиваем и порог разбиения t.
- Ищутся они полным перебором по всем j и t по некоторому критерию качества Q(R_m, j, t), где R_m - объекты в текущей вершины. Критерий качества разбиения — impurity, хаотичность.
- Можно интерпретировать так: если константой можно добиться низкой ошибки, хаотичность низкая.
- Для регрессии этой хаотичностью может быть дисперсия, для классификации например кросс-энтропия.

Подробнее про критерии:

- Индекс Джини (измеряет вероятность того, что случайно выбранный элемент из набора будет неправильно классифицирован, если его классифицировать случайным образом). Это 1 минус сумма квадратов долей объектов каждого класса в узле.
- Кросс-энтропия - измеряет снижение энтропии (хаотичности) при разбиении данных
- Information Gain - информационный выигрыш, считает разницу между хаотичностью до и хаотичностью после, так как мы хотим максимизировать разницу в хаотичности.

## - Что такое случайный лес и градиентный бустинг? В чем их отличия? Как они борются с переобучением? В чем различие между бэггингом и бустингом? 

---

### Случайный лес (Random Forest) 

- Случайный лес — это метод на основе бэггинга (bagging), который создаёт множество деревьев решений, используя случайные подвыборки данных и случайные подмножества признаков. Итоговое предсказание получается путём усреднения (в регрессии) или голосования (в классификации) всех деревьев.

Как он работает:

- Из обучающей выборки создаются подвыборки (с возвращением) того же размера — для каждого дерева.
- Для каждого узла в дереве случайно выбирается подмножество признаков, чтобы уменьшить корреляцию между деревьями.
- Деревья обучаются независимо друг от друга, и итоговое предсказание — это результат голосования или усреднения по всем деревьям.
- Борьба с переобучением: благодаря случайности в отборе данных и признаков, деревья в случайном лесе становятся менее зависимыми друг от друга и менее склонны к переобучению. Это делает случайный лес устойчивым к шуму в данных.

### Градиентный бустинг (Gradient Boosting) 

- Градиентный бустинг — это метод на основе бустинга (boosting), который строит деревья последовательно, каждый раз корректируя ошибки предыдущих деревьев. Вместо случайного подбора деревьев, каждый новый этап пытается минимизировать ошибку модели.

Как он работает:

- Первое дерево обучается на данных и делает предсказания.
- Следующее дерево обучается на остатках (разнице между истинными значениями и предсказаниями первого дерева), чтобы исправить ошибки.
- Этот процесс повторяется, добавляя деревья, которые пытаются уменьшить ошибку предсказаний предыдущих деревьев.
- Борьба с переобучением: градиентный бустинг может быть подвержен переобучению, особенно на глубоких деревьях. Чтобы бороться с этим, используются техники, такие как регуляризация, уменьшение глубины деревьев, шаг обучения (learning rate), который контролирует влияние каждого дерева, и ранняя остановка (early stopping).
- Более подробно: мы хотим заставить очередную модель композиции исправлять ошибки уже построенной композиции. Для этого мы считаем сдвиг для каждого объекта обучающих данных через частрую производную по построенной композиции. Фактически, здесь мы делаем градиентный спуск в пространстве ответов композиций обучающей выборки. Так вот, посчитали сдвиги. Далее мы стремимся очередной моделью (очередным деревом) минимизировать разницу между этой моделью и сдвигом и таким образом получаем очередную модель, которую суммируем к ранее построенной композиции. Ну и для всех объектов, считая сдвиги, мы по факту считаем полный градиент функционала ошибки.

### Отличия между случайным лесом и градиентным бустингом 

- Метод построения ансамбля: Случайный лес использует бэггинг и строит деревья параллельно, каждая модель работает независимо. Градиентный бустинг использует бустинг и строит деревья последовательно, добавляя каждое новое дерево для исправления ошибок предыдущих.
- Скорость обучения и предсказания: Случайный лес быстрее обучается, так как деревья строятся параллельно. Градиентный бустинг обычно медленнее, так как деревья строятся последовательно, и требуется больше итераций.
- Чувствительность к переобучению: Случайный лес менее склонен к переобучению благодаря случайности, добавляемой в каждое дерево. Градиентный бустинг склонен к переобучению, особенно если деревья глубокие. Требует более тщательной настройки гиперпараметров.

### Различие между бэггингом и бустингом 

- Бэггинг (Bagging — Bootstrap Aggregating): В бэггинге модели обучаются независимо друг от друга на случайных подвыборках данных. Финальное предсказание получается путём усреднения или голосования результатов всех моделей. Бэггинг уменьшает дисперсию модели и делает её устойчивой к переобучению. Пример: случайный лес.
    
- Бустинг (Boosting): В бустинге модели строятся последовательно, каждая новая модель исправляет ошибки предыдущих. Финальное предсказание — это взвешенная сумма предсказаний всех моделей. Бустинг уменьшает смещение модели, но повышает её чувствительность к переобучению. Примеры: градиентный бустинг, AdaBoost.
    
- Итог: Случайный лес более устойчив к переобучению, так как использует случайность для уменьшения корреляции между деревьями, в то время как градиентный бустинг лучше исправляет ошибки и подходит для более сложных задач, но требует тщательной настройки для борьбы с переобучением.




1. Что такое шум?
2. Как его можно отфильтровать?
3. Какие есть разложения матриц?
4. SVD
5. Ошибка обучения
6. Лосс-функция
7. Отличия лосса от метрик
8. Domain gap
9. Что делать, если выборка несбалансированна?
10. Переобучение и как бороться с ним?
11. Как следить за переобучением?
12. Почему не пользуемся аналитической формулой при решении задачи регрессии со среднеквадратичной ошибкой, а пользуемся градиентным спуском? Что здесь самое тяжелое в плане вычислений? Может быть еще какие-нибудь минусы есть?
13. Что такое бэггинг?
14. Что будет, если мы сделаем бэггинг над линейными алгоритмами?
15. Почему с деревьями бэггинг работает, что мы там используем, чтобы бэггинг работал?16. Выбор подмножества фичей мы выбираем в отдельных вершинах дерева или у всего дерева целиком?
16. Что больше склонно к переобучению, случайный лес или градиентный бустинг?
17. Какой глубины деревья используются в случайном лесе и в градиентном бустинге? (насколько бы мы ограничивали глубину в обоих вариантах)
18. Почему бустинг градиентный и где здесь градиент? Какая будет целевая переменная у n-ого дерева?
19. Какие реализации помнишь градиентного бустинга? Какие у них различия?
20. Есть случайный лес, есть градиентный бустинг, почему в промышленной среде, особенно в задачах, где нужен быстрый инференс, используют бустинг, а не случайный лес?
21. Ты решаешь задачу регрессии, есть выбросы, почистить не можешь. Какую метрику предпочтешь оптимизировать, MSE/MAE?
22. Какие метрики классификации помнишь?
23. Подробнее про precision и recall.
24. Что такое ROC-AUC?
25. Решали задачу бинарной классификации, получили ROC-AUC 0.92. Как он изменится, если продублировать в выборке все объекты положительного класса 7 раз, а отрицательного класса 5 раз?
26. Какие способы регуляризации нейронов ты знаешь?
27. Как происходит регуляризация в линейных моделях?
28. Метрики P, R, A, F1. Формула F1, что такое гармоническое среднее, как в оригинале выглядит F, зачем там B, что она дает?
29. Чем плоха accuracy? Есть accuracy 0.78 и 0.82, какую выберешь, почему?
30. PR-кривая: что такое, для чего нужна, как подбирать порог с помощью PR-кривой?
31. AUC-ROC: что такое, зачем нужна, какую ещё задачу может решать (ранжирования). Что будет, если домножить на log? Если на -1?
32. Что такое bias-variance tradeoff?
33. Если bias выше, это недообучение или переобучение?
34. Если регулизировать веса в линейной и логистической регрессии, как меняется bias-variance?
35. Если в KNN увеличить K, что будет с bias-variance?
36. Если ограничивать глубину дерева, что будет с bias-variance?
37. Если использовать dropout в нейросетях, что будет с bias-variance?
38. Какие ансамблевые методы знаешь?
39. Чем отличается бустинг и бэггинг?
40. Как посчитать градиент в точке?
41. Какой будет ROC-AUC, если модель рандомная? А какой, если у нас 99% и 1% дисбаланс классов и модель константная?
42. Что такое случайный лес?
43. Как обрабатываются категориальные признаки?
44. Как работает критерий Джинни?
45. Что такое энтропия?
46. Что такое информативность относительно признаков?
47. Насколько сильно понижается дисперсия после ансамблирования?
48. Где градиент в градиентном бустинге?
49. Почему L1 зануляет веса, а L2 нет?
50. В задачах ранжирования: какие метрики знаете?
51. Какие метрики для регрессии знаете?
52. Как производить отбор фичей, понижать размерность датасета?
53. Как работает PCA?
54. Как работает метод главных компонент?
55. Какие методы идентификации выбросов знаешь?
56. Что такое корреляция и ковариация? Как они связаны?
57. Что такое мультиколлинеарность, и надо ли с ней бороться в логистической регрессии?
58. Что такое bagging, boosting?
59. Как деревья выбирают порог отсечения?
60. Что такое bias, variance, шум?
61. Какие способы борьбы с переобучением знаешь?
62. Что делать, если дисбаланс классов?
63. Как понять, что рекомендации хорошо работают?
64. Как понять связь оффлайн и онлайн метрик?
65. Какие тесты используются для сравнения выборок?
66. Как бороться с нулями и NaN в данных?
67. Как вычислить длину вектора? Что такое скаляр?
68. Какие алгоритмы кластеризации знаешь? Чем отличается K-Means от K-Means++?
69. Что такое деревья решений? Как обучаются деревья в случайном лесе и градиентном бустинге?
70. Какие способы отбора признаков знаешь?
71. Что такое forward-backward selection?
72. Какие метрики устойчивы к дисбалансу классов?
73. Как узнать оптимальное количество кластеров для K-Means?
74. Почему иногда лучше ROC-AUC, а не precision, recall, accuracy?
75. В объявлении нельзя указывать свой номер телефона. Нужно выбрать порог для выбора между автоматическим отклонением и отправкой на ручную модерацию. Какую метрику выберешь?
76. Зачем нужна функция активации в нейронных сетях?
77. Как происходит обучение линейной модели? Что ищет линейная регрессия?
78. Что оптимизирует линейная регрессия?
79. Зачем нужна кросс-валидация? Какие плюсы и минусы?
80. Какая глубина деревьев нужна для случайного леса и бустинга?
81. Может ли случайный лес переобучаться при увеличении количества деревьев? А градиентный бустинг?
82. Как бороться с выбросами? Какие метрики предпочесть, если есть выбросы?
83. Почему не стоит оптимизировать метрики вроде accuracy напрямую?
84. Какие способы ансамблирования знаешь?
85. Почему кросс-энтропия является хорошей функцией потерь для классификации?
86. Какие деревья используются в бустинге и случайном лесе? Почему они разные?
87. Что будет, если использовать линейные алгоритмы в случайном лесе?
88. Если добавить в выборку много одинаковых объектов, как изменятся метрики?
89. Какие способы нормализации данных знаешь? Всегда ли это нужно для деревьев?