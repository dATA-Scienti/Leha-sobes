1. Что такое шум?
2. Как его можно отфильтровать?
3. Какие есть разложения матриц?
4. SVD
5. Ошибка обучения
6. Лосс-функция
7. Отличия лосса от метрик
8. Domain gap
9. Что делать, если выборка несбалансированна?
10. Переобучение и как бороться с ним?
11. Как следить за переобучением?
12. Почему не пользуемся аналитической формулой при решении задачи регрессии со среднеквадратичной ошибкой, а пользуемся градиентным спуском? Что здесь самое тяжелое в плане вычислений? Может быть еще какие-нибудь минусы есть?
13. Что такое бэггинг?
14. Что будет, если мы сделаем бэггинг над линейными алгоритмами?
15. Почему с деревьями бэггинг работает, что мы там используем, чтобы бэггинг работал?16. Выбор подмножества фичей мы выбираем в отдельных вершинах дерева или у всего дерева целиком?
16. Что больше склонно к переобучению, случайный лес или градиентный бустинг?
17. Какой глубины деревья используются в случайном лесе и в градиентном бустинге? (насколько бы мы ограничивали глубину в обоих вариантах)
18. Почему бустинг градиентный и где здесь градиент? Какая будет целевая переменная у n-ого дерева?
19. Какие реализации помнишь градиентного бустинга? Какие у них различия?
20. Есть случайный лес, есть градиентный бустинг, почему в промышленной среде, особенно в задачах, где нужен быстрый инференс, используют бустинг, а не случайный лес?
21. Ты решаешь задачу регрессии, есть выбросы, почистить не можешь. Какую метрику предпочтешь оптимизировать, MSE/MAE?
22. Какие метрики классификации помнишь?
23. Подробнее про precision и recall.
24. Что такое ROC-AUC?
25. Решали задачу бинарной классификации, получили ROC-AUC 0.92. Как он изменится, если продублировать в выборке все объекты положительного класса 7 раз, а отрицательного класса 5 раз?
26. Какие способы регуляризации нейронов ты знаешь?
27. Как происходит регуляризация в линейных моделях?
28. Метрики P, R, A, F1. Формула F1, что такое гармоническое среднее, как в оригинале выглядит F, зачем там B, что она дает?
29. Чем плоха accuracy? Есть accuracy 0.78 и 0.82, какую выберешь, почему?
30. PR-кривая: что такое, для чего нужна, как подбирать порог с помощью PR-кривой?
31. AUC-ROC: что такое, зачем нужна, какую ещё задачу может решать (ранжирования). Что будет, если домножить на log? Если на -1?
32. Что такое bias-variance tradeoff?
33. Если bias выше, это недообучение или переобучение?
34. Если регулизировать веса в линейной и логистической регрессии, как меняется bias-variance?
35. Если в KNN увеличить K, что будет с bias-variance?
36. Если ограничивать глубину дерева, что будет с bias-variance?
37. Если использовать dropout в нейросетях, что будет с bias-variance?
38. Какие ансамблевые методы знаешь?
39. Чем отличается бустинг и бэггинг?
40. Как посчитать градиент в точке?
41. Какой будет ROC-AUC, если модель рандомная? А какой, если у нас 99% и 1% дисбаланс классов и модель константная?
42. Что такое случайный лес?
43. Как обрабатываются категориальные признаки?
44. Как работает критерий Джинни?
45. Что такое энтропия?
46. Что такое информативность относительно признаков?
47. Насколько сильно понижается дисперсия после ансамблирования?
48. Где градиент в градиентном бустинге?
49. Почему L1 зануляет веса, а L2 нет?
50. В задачах ранжирования: какие метрики знаете?
51. Какие метрики для регрессии знаете?
52. Как производить отбор фичей, понижать размерность датасета?
53. Как работает PCA?
54. Как работает метод главных компонент?
55. Какие методы идентификации выбросов знаешь?
56. Что такое корреляция и ковариация? Как они связаны?
57. Что такое мультиколлинеарность, и надо ли с ней бороться в логистической регрессии?
58. Что такое bagging, boosting?
59. Как деревья выбирают порог отсечения?
60. Что такое bias, variance, шум?
61. Какие способы борьбы с переобучением знаешь?
62. Что делать, если дисбаланс классов?
63. Как понять, что рекомендации хорошо работают?
64. Как понять связь оффлайн и онлайн метрик?
65. Какие тесты используются для сравнения выборок?
66. Как бороться с нулями и NaN в данных?
67. Как вычислить длину вектора? Что такое скаляр?
68. Какие алгоритмы кластеризации знаешь? Чем отличается K-Means от K-Means++?
69. Что такое деревья решений? Как обучаются деревья в случайном лесе и градиентном бустинге?
70. Какие способы отбора признаков знаешь?
71. Что такое forward-backward selection?
72. Какие метрики устойчивы к дисбалансу классов?
73. Как узнать оптимальное количество кластеров для K-Means?
74. Почему иногда лучше ROC-AUC, а не precision, recall, accuracy?
75. В объявлении нельзя указывать свой номер телефона. Нужно выбрать порог для выбора между автоматическим отклонением и отправкой на ручную модерацию. Какую метрику выберешь?
76. Зачем нужна функция активации в нейронных сетях?
77. Как происходит обучение линейной модели? Что ищет линейная регрессия?
78. Что оптимизирует линейная регрессия?
79. Зачем нужна кросс-валидация? Какие плюсы и минусы?
80. Какая глубина деревьев нужна для случайного леса и бустинга?
81. Может ли случайный лес переобучаться при увеличении количества деревьев? А градиентный бустинг?
82. Как бороться с выбросами? Какие метрики предпочесть, если есть выбросы?
83. Почему не стоит оптимизировать метрики вроде accuracy напрямую?
84. Какие способы ансамблирования знаешь?
85. Почему кросс-энтропия является хорошей функцией потерь для классификации?
86. Какие деревья используются в бустинге и случайном лесе? Почему они разные?
87. Что будет, если использовать линейные алгоритмы в случайном лесе?
88. Если добавить в выборку много одинаковых объектов, как изменятся метрики?
89. Какие способы нормализации данных знаешь? Всегда ли это нужно для деревьев?