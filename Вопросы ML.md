# Изи 

1. Что такое шум?
2. Как его можно отфильтровать?
3. Ошибка обучения
4. Лосс-функция
5. Отличия лосса от метрик
6. Что делать, если выборка несбалансированна?
7. Переобучение и как бороться с ним?
8. Что такое бэггинг?
9. Какие метрики классификации помнишь?
10. Подробнее про precision и recall.
11. Что такое ROC-AUC?
12. Какие способы регуляризации нейронов ты знаешь?
13. Как происходит регуляризация в линейных моделях?
14. Чем плоха accuracy?
15. Что такое случайный лес?
16. Как обрабатываются категориальные признаки?    
17. Что такое энтропия?
18. Какие метрики для регрессии знаешь?
19. Как работает PCA?
20. Какие методы идентификации выбросов знаешь?
21. Что такое корреляция и ковариация? Как они связаны?
22. Какие способы борьбы с переобучением знаешь?
23. Как бороться с нулями и NaN в данных?
24. Какие алгоритмы кластеризации знаешь?
25. Что такое деревья решений?
26. Зачем нужна функция активации в нейронных сетях?
27. Что оптимизирует линейная регрессия?
28. Зачем нужна кросс-валидация? Какие плюсы и минусы?

# Медиум

1. Как следить за переобучением?
2. Почему не пользуемся аналитической формулой при решении задачи регрессии со среднеквадратичной ошибкой, а пользуемся градиентным спуском?
3. Что будет, если мы сделаем бэггинг над линейными алгоритмами?
4. Почему с деревьями бэггинг работает, что мы там используем, чтобы бэггинг работал?
5. Выбор подмножества фичей мы выбираем в отдельных вершинах дерева или у всего дерева целиком?
6. Как работает критерий Джинни? (знать не обязательно)
7. Что больше склонно к переобучению, случайный лес или градиентный бустинг?
8. Какой глубины деревья используются в случайном лесе и в градиентном бустинге?
9. Почему бустинг градиентный и где здесь градиент? Какая будет целевая переменная у n-ого дерева?
10. Какие реализации помнишь градиентного бустинга? Какие у них различия?
11. Почему в промышленной среде, особенно в задачах, где нужен быстрый инференс, используют бустинг, а не случайный лес?
12. Ты решаешь задачу регрессии, есть выбросы, почистить не можешь. Какую метрику предпочтешь оптимизировать, MSE/MAE?
13. Решали задачу бинарной классификации, получили ROC-AUC 0.92. Как он изменится, если продублировать в выборке все объекты положительного класса 7 раз, а отрицательного класса 5 раз?
14. Метрики P, R, A, F1. Формула F1, что такое гармоническое среднее, как в оригинале выглядит F, зачем там B, что она дает?
15. PR-кривая: что такое, для чего нужна, как подбирать порог с помощью PR-кривой?
16. AUC-ROC: что такое, зачем нужна, какую ещё задачу может решать (ранжирования). Что будет, если домножить на log? Если на -1?
17. Что такое bias-variance tradeoff?
18. Как меняется bias-variance при различных методах регуляризации и настройках моделей?
19. Какой будет ROC-AUC, если модель рандомная? А какой, если у нас 99% и 1% дисбаланс классов и модель константная?
20. Что такое информативность относительно признаков?
21. Насколько сильно понижается дисперсия после ансамблирования?
22. Почему L1 зануляет веса, а L2 нет?
23. В задачах ранжирования: какие метрики знаете?
24. Как производить отбор фичей, понижать размерность датасета?
25. Что такое мультиколлинеарность, и надо ли с ней бороться в логистической регрессии?
26. Как деревья выбирают порог отсечения?
27. Как понять, что рекомендации хорошо работают?
28. Как понять связь оффлайн и онлайн метрик?
29. Какие тесты используются для сравнения выборок?
30. Чем отличается K-Means от K-Means++?
31. Как обучаются деревья в случайном лесе и градиентном бустинге?
32. Что такое forward-backward selection?
33. Какие метрики устойчивы к дисбалансу классов?
34. Как узнать оптимальное количество кластеров для K-Means?
35. В объявлении нельзя указывать свой номер телефона. Нужно выбрать порог для выбора между автоматическим отклонением и отправкой на ручную модерацию. Какую метрику выберешь? (важно мышление)
36. Может ли случайный лес переобучаться при увеличении количества деревьев? А градиентный бустинг?
37. Почему не стоит оптимизировать метрики вроде accuracy напрямую?
38. Почему кросс-энтропия является хорошей функцией потерь для классификации?
